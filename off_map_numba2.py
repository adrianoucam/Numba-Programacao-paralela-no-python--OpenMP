
'''
problema acad√™mico desenhado para ser resolvido com o algoritmo (as tr√™s ‚Äúregi√µes target‚Äù com map(to:), map(from:) e map(alloc:) ‚Äî na sua vers√£o em Numba/CPU paralelo):

Problema ‚Äî Fus√£o de sinais com buffer tempor√°rio e regi√£o de interesse (ROI) em pipeline heterog√™neo
Contexto

Voc√™ tem dois sinais 1-D sincronizados (ex.: dois sensores distintos de um sistema ciber-f√≠sico). Deseja:

Fundir os sinais por soma ponto-a-ponto (est√°gio 1);

Preparar um buffer tempor√°rio interno ao ‚Äúdispositivo‚Äù para normaliza√ß√£o/uso posterior (est√°gio 2);

Refinar uma regi√£o de interesse (ROI) (primeira metade do vetor) sobrescrevendo a fus√£o por um realce simples (est√°gio 3).

O objetivo √© praticar pol√≠ticas de mapeamento de dados (to/from/alloc) e paralelismo em um pipeline de tr√™s est√°gios.

Dados (entrada)

Inteiro 
ùëÅ
‚â•
10
N‚â•10 (tamanho do vetor).

Vetores inteiros 
ùëé
,
ùëè
‚àà
ùëç
ùëÅ
a,b‚ààZ
N
.

ROI fixa: os primeiros 
ùëÅ
/
2
N/2 elementos.

Para valida√ß√£o did√°tica, use inicialmente:

ùëÅ
=
10
N=10, 
ùëé
[
ùëñ
]
=
ùëñ
+
1
a[i]=i+1, 
ùëè
[
ùëñ
]
=
2
(
ùëñ
+
1
)
b[i]=2(i+1), 
ùëñ
=
0
,
‚Ä¶
,
9
i=0,‚Ä¶,9.

Pipeline a implementar

Est√°gio 1 (fus√£o): map(to: a,b) e map(from: c)

ùëê
[
ùëñ
]
‚Üê
ùëé
[
ùëñ
]
+
ùëè
[
ùëñ
]
c[i]‚Üêa[i]+b[i], 
ùëñ
=
0
,
‚Ä¶
,
ùëÅ
‚àí
1
i=0,‚Ä¶,N‚àí1.

Est√°gio 2 (buffer tempor√°rio): map(to: a) e map(alloc: x)

ùë•
[
ùëñ
]
‚Üê
2
‚Äâ
ùëé
[
ùëñ
]
x[i]‚Üê2a[i], usar 
ùë•
x apenas dentro da regi√£o para computar um escalar (ex.: soma ou m√©dia) e n√£o devolver 
ùë•
x ao hospedeiro. Retorne apenas esse escalar (ex.: 
s
u
m
(
ùë•
)
sum(x)).

Est√°gio 3 (refino na ROI): map(to: a[0:N/2]) e map(from: c[0:N/2])
Para 
ùëñ
=
0
,
‚Ä¶
,
ùëÅ
/
2
‚àí
1
i=0,‚Ä¶,N/2‚àí1: 
ùëê
[
ùëñ
]
‚Üê
2
‚Äâ
ùëé
[
ùëñ
]
c[i]‚Üê2a[i].
(Os elementos 
ùëê
[
ùëÅ
/
2
]
,
‚Ä¶
,
ùëê
[
ùëÅ
‚àí
1
]
c[N/2],‚Ä¶,c[N‚àí1] permanecem como sa√≠ram do Est√°gio 1.)

Observa√ß√£o: Em Numba/CPU, ‚Äúmap‚Äù √© modelado por assinatura de fun√ß√£o / retorno (passagem de dados) e aloca√ß√£o local; o conceito did√°tico √© o mesmo: o que entra, o que sai e o que existe s√≥ dentro.

Sa√≠da esperada (caso de teste 
ùëÅ
=
10
N=10)

Ap√≥s Est√°gio 1: 
ùëê
=
[
3
,
6
,
9
,
12
,
15
,
18
,
21
,
24
,
27
,
30
]
c=[3,6,9,12,15,18,21,24,27,30].

Ap√≥s Est√°gio 3 (ROI = 5 primeiros):

ùëê
=
[
2
,
4
,
6
,
8
,
10
,
18
,
21
,
24
,
27
,
30
]
c=[2,4,6,8,10,18,21,24,27,30].

Est√°gio 2: retorne um escalar (ex.: 
s
u
m
(
ùë•
)
=
‚àë
2
ùëé
[
ùëñ
]
=
2
‚àë
(
ùëñ
+
1
)
=
2
‚ãÖ
55
=
110
sum(x)=‚àë2a[i]=2‚àë(i+1)=2‚ãÖ55=110) sem materializar 
ùë•
x no hospedeiro.

Tarefas

Implemente os tr√™s est√°gios em fun√ß√µes separadas com Numba:

Est√°gios 1 e 3 com @njit(parallel=True) e prange.

Est√°gio 2 com @njit(parallel=True), alocando x localmente e retornando s√≥ um escalar.

Verifique a corre√ß√£o no caso 
ùëÅ
=
10
N=10 e imprima o vetor 
ùëê
c final e o escalar do Est√°gio 2.

Experimentos de desempenho:

Varie 
ùëÅ
‚àà
{
10
6
,
2
‚ãÖ
10
6
,
5
‚ãÖ
10
6
}
N‚àà{10
6
,2‚ãÖ10
6
,5‚ãÖ10
6
} (ajuste √† sua RAM).

Me√ßa o tempo de cada est√°gio separadamente.

Calcule speedup e efici√™ncia do Est√°gio 1 e do Est√°gio 3 (paralelos) versus uma vers√£o sequencial (mesma l√≥gica sem prange).

An√°lise de tr√°fego de mem√≥ria (modelagem):

Estime, em bytes, o volume l√≥gico de leitura/escrita por est√°gio:

E1: l√™ 
ùëé
,
ùëè
a,b (2N elementos), escreve 
ùëê
c (N).

E2: l√™ 
ùëé
a (N), escreve 
ùë•
x (N, n√£o retorna), l√™ 
ùë•
x para reduzir (N).

E3: l√™ 
ùëé
[
0
:
ùëÅ
/
2
]
a[0:N/2], escreve 
ùëê
[
0
:
ùëÅ
/
2
]
c[0:N/2].

Discuta como map(alloc:) reduz tr√°fego de ida/volta (na analogia com um device real).

Discuss√£o t√©cnica:

Quando e por que preferir alloc em vez de to/from para buffers tempor√°rios?

Como a escolha do tamanho da ROI impacta o tempo do Est√°gio 3?

Identifique gargalos de mem√≥ria (bound) vs CPU (compute-bound).

Crit√©rios de avalia√ß√£o

Corre√ß√£o funcional (valores esperados no caso 
ùëÅ
=
10
N=10).

Qualidade do paralelismo (uso adequado de prange, aus√™ncia de race conditions).

Metodologia de medi√ß√£o (warm-up do JIT, m√∫ltiplas repeti√ß√µes, m√©dia/mediana).

An√°lise de tr√°fego e discuss√£o sobre map(alloc:).

Clareza do relat√≥rio (1‚Äì2 p√°ginas) com tabelas de tempo, speedup e efici√™ncia.

Extens√µes (opcional)

Generalize o Est√°gio 3 para uma ROI din√¢mica 
[
ùêø
,
ùëà
)
[L,U) e compare tempos.

Substitua o Est√°gio 2 por uma normaliza√ß√£o z-score usando apenas o escalar retornado (m√©dia) e um segundo passe para o desvio-padr√£o ‚Äî ainda sem retornar x.

Compare com uma implementa√ß√£o equivalente em OpenMP/C com target real e discuta diferen√ßas pr√°ticas (lat√™ncia PCIe, pinning, pageable vs pinned).


'''



# pipeline_map_numba_bench.py
# Est√°gio 1: c = a + b            (map(to: a,b) map(from: c))
# Est√°gio 2: x = 2*a (alloc)      (map(to: a)   map(alloc: x))  -> retorna apenas soma(x)
# Est√°gio 3: c[0:N/2] = 2*a[...]  (map(to: a[0:N/2]) map(from: c[0:N/2]))

import time
import numpy as np
from numba import njit, prange, set_num_threads

# ---------------------------
# Implementa√ß√µes SEQ e PAR
# ---------------------------

@njit
def stage1_seq(a, b):
    n = a.size
    c = np.empty_like(a)
    for i in range(n):
        c[i] = a[i] + b[i]
    return c

@njit(parallel=True)
def stage1_par(a, b):
    n = a.size
    c = np.empty_like(a)
    for i in prange(n):
        c[i] = a[i] + b[i]
    return c

@njit
def stage2_seq_sumx(a):
    # x √© "alloc" (tempor√°rio); retornamos somente a soma(x)
    n = a.size
    acc = 0
    for i in range(n):
        acc += 2 * a[i]
    return acc

@njit(parallel=True)
def stage2_par_sumx(a):
    # redu√ß√£o paralela suportada pelo Numba para += em escalar simples
    n = a.size
    acc = 0
    for i in prange(n):
        acc += 2 * a[i]
    return acc

@njit
def stage3_seq(a, c):
    # modifica apenas a metade inicial de c
    n2 = a.size // 2
    for i in range(n2):
        c[i] = 2 * a[i]

@njit(parallel=True)
def stage3_par(a, c):
    n2 = a.size // 2
    for i in prange(n2):
        c[i] = 2 * a[i]

# ---------------------------
# Utilidades de benchmark
# ---------------------------

def _median(x):
    y = sorted(x)
    m = len(y) // 2
    return (y[m] if len(y) % 2 else 0.5 * (y[m - 1] + y[m]))

def bench_stage1(N, n_threads, reps=3):
    # dados
    a = np.arange(1, N + 1, dtype=np.int32)
    b = 2 * a

    # warm-up JIT
    _ = stage1_seq(a[:1], b[:1])
    _ = stage1_par(a[:1], b[:1])

    # seq
    t_seq = []
    for _r in range(reps):
        t0 = time.perf_counter()
        c1 = stage1_seq(a, b)
        t1 = time.perf_counter()
        t_seq.append(t1 - t0)

    # par
    set_num_threads(n_threads)
    t_par = []
    for _r in range(reps):
        t0 = time.perf_counter()
        c2 = stage1_par(a, b)
        t1 = time.perf_counter()
        t_par.append(t1 - t0)

    ok = np.array_equal(c1, c2)
    return _median(t_seq), _median(t_par), ok

def bench_stage3(N, n_threads, reps=3):
    a = np.arange(1, N + 1, dtype=np.int32)
    # c inicial vem do est√°gio 1 (por exemplo); aqui simulamos qualquer estado
    c_seq = np.zeros(N, dtype=np.int32)
    c_par = np.zeros(N, dtype=np.int32)

    # warm-up JIT
    _ = stage3_seq(a[:2], c_seq[:2])
    _ = stage3_par(a[:2], c_par[:2])

    # seq
    t_seq = []
    for _r in range(reps):
        c_seq[:] = 0
        t0 = time.perf_counter()
        stage3_seq(a, c_seq)
        t1 = time.perf_counter()
        t_seq.append(t1 - t0)

    # par
    set_num_threads(n_threads)
    t_par = []
    for _r in range(reps):
        c_par[:] = 0
        t0 = time.perf_counter()
        stage3_par(a, c_par)
        t1 = time.perf_counter()
        t_par.append(t1 - t0)

    # conferir apenas metade alterada; resto igual (zero)
    ok = np.array_equal(c_seq, c_par)
    return _median(t_seq), _median(t_par), ok

# ---------------------------
# Demonstra√ß√£o did√°tica N=10
# ---------------------------

def demo_N10():
    N = 10
    a = np.arange(1, N + 1, dtype=np.int32)
    b = 2 * a

    # warm-ups m√≠nimos
    _ = stage1_seq(a[:1], b[:1]); _ = stage1_par(a[:1], b[:1])
    _ = stage2_seq_sumx(a[:1]);   _ = stage2_par_sumx(a[:1])
    c_demo = stage1_par(a, b)  # est√°gio 1 (paralelo)
    sumx   = stage2_par_sumx(a) # est√°gio 2 (paralelo)
    stage3_par(a, c_demo)       # est√°gio 3 (paralelo)

    print("Demonstra√ß√£o N=10")
    print("a =", a.tolist())
    print("b =", b.tolist())
    # Ap√≥s est√°gio 1: soma ponto-a-ponto
    c_stage1 = stage1_seq(a, b)
    print("Ap√≥s Est√°gio 1 (c = a + b):", c_stage1.tolist())
    # Est√°gio 2: soma(x) com x=2*a (alloc)
    print("Est√°gio 2 (soma de x=2*a):", int(sumx))
    # Est√°gio 3: metade inicial substitu√≠da por 2*a
    print("Ap√≥s Est√°gio 3 (ROI 0..N/2-1):", c_demo.tolist())
    # valores esperados:
    # c_stage1 = [3,6,9,12,15,18,21,24,27,30]
    # c_final  = [2,4,6,8,10,18,21,24,27,30]
    # sumx     = 2 * sum(1..10) = 2 * 55 = 110

# ---------------------------
# Main: benchmark + demo
# ---------------------------

def main():
    demo_N10()
    print("\n==== Benchmark ====")
    # escolha um N que caiba na sua RAM
    N_BENCH = 2_000_000
    threads_list = [1, 2, 4, 8]

    # Stage 1
    print("\n[Est√°gio 1] c = a + b")
    # refer√™ncia sequencial (com 1 thread)
    t_seq_ref, _, ok = bench_stage1(N_BENCH, n_threads=1, reps=3)
    if not ok:
        print("Aviso: diverg√™ncia Stage 1 com 1 thread.")
    print("t_seq_ref = %.6f s" % t_seq_ref)
    print("Threads | t_par (s) | Speedup | Efici√™ncia")
    print("--------+-----------+---------+-----------")
    for nt in threads_list:
        t_seq, t_par, ok = bench_stage1(N_BENCH, n_threads=nt, reps=3)
        speed = (t_seq_ref / t_par) if t_par > 0 else float("inf")
        eff   = speed / nt
        print("%7d | %9.6f | %7.3f | %9.3f" % (nt, t_par, speed, eff))
        if not ok:
            print("  * diverg√™ncia detectada (Stage 1)")

    # Stage 3
    print("\n[Est√°gio 3] c[0:N/2] = 2*a[0:N/2]")
    # refer√™ncia sequencial (com 1 thread)
    t_seq_ref, _, ok = bench_stage3(N_BENCH, n_threads=1, reps=3)
    if not ok:
        print("Aviso: diverg√™ncia Stage 3 com 1 thread.")
    print("t_seq_ref = %.6f s" % t_seq_ref)
    print("Threads | t_par (s) | Speedup | Efici√™ncia")
    print("--------+-----------+---------+-----------")
    for nt in threads_list:
        t_seq, t_par, ok = bench_stage3(N_BENCH, n_threads=nt, reps=3)
        speed = (t_seq_ref / t_par) if t_par > 0 else float("inf")
        eff   = speed / nt
        print("%7d | %9.6f | %7.3f | %9.3f" % (nt, t_par, speed, eff))
        if not ok:
            print("  * diverg√™ncia detectada (Stage 3)")

    print("\nObserva√ß√µes:")
    print("- Use set_num_threads(k) se quiser fixar manualmente os threads.")
    print("- A paraleliza√ß√£o aqui √© *data-parallel* e bound por mem√≥ria; ganhos saturam.")
    print("- A etapa 2 demonstra 'map(alloc: x)': x n√£o retorna ao host (retornamos s√≥ soma(x)).")
    print("- Aumente N_BENCH se quiser estressar mais a banda de mem√≥ria, respeitando sua RAM.")

if __name__ == "__main__":
    main()
