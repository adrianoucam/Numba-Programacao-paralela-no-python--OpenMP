# Numba-Programacao-paralela-no-python--OpenMP
Numba Programacao paralela no python- OpenMP

Numba + (OpenMP â†’ Python) â€” Guia e Exemplos

Este repositÃ³rio reÃºne traduÃ§Ãµes de padrÃµes do OpenMP para Python com Numba e alguns exercÃ­cios/benchmarks. A ideia Ã© mostrar, na prÃ¡tica, como mapear parallel for, collapse, private/firstprivate, map(to/from/alloc), dependÃªncias entre regiÃµes, e atÃ© MPI + Numba para execuÃ§Ã£o hÃ­brida.

Todos os cÃ³digos estÃ£o em Python 3.10+ com Numba e NumPy. Onde indicado, hÃ¡ variaÃ§Ãµes com mpi4py e (opcionalmente) CUDA.

Requisitos

Python 3.10 ou 3.11

numpy

numba

(opcional) mpi4py + OpenMPI/MPICH para a versÃ£o distribuÃ­da

(opcional) CUDA Toolkit â‰¥ 11.2 para usar Numba-CUDA (se aplicÃ¡vel)

InstalaÃ§Ã£o rÃ¡pida (via conda)
conda create -n numba-playground python=3.11 numpy numba -c conda-forge -y
conda activate numba-playground

# Para MPI:
conda install mpi4py -c conda-forge -y
# (instale OpenMPI/MPICH do seu sistema, se necessÃ¡rio)


Dicas (Numba vs OpenMP)

#pragma omp parallel for â†’ @njit(parallel=True) + prange(...).

collapse(2) â†’ linearizar (k,j) em um Ãºnico Ã­ndice idx com prange(total).

private â†’ variÃ¡vel local dentro do loop; firstprivate â†’ passar por valor como argumento.

map(to/from/alloc) â†’ modelar com assinatura/retorno de funÃ§Ã£o e alocaÃ§Ã£o local.

reduction(max: dt) â†’ usar reduÃ§Ã£o em duas fases (mÃ¡ximos por linha â†’ mÃ¡ximo global).

single/critical â†’ organizar a lÃ³gica no host; seleÃ§Ãµes globais baratas podem ficar sequenciais.

prange sÃ³ aceita passo 1.

Evite f"{i:2d}" em @njit: use concatenaÃ§Ã£o ("texto "+str(i)) ou "%d".

Controle de threads (por processo):

# Windows (cmd)
set NUMBA_NUM_THREADS=8

# Linux/macOS
export NUMBA_NUM_THREADS=8


Exemplos & Scripts
1) Barreira e regiÃ£o paralela

Arquivo: numba_barreira.py
Mostra: simulaÃ§Ã£o de omp barrier (a â€œesperaâ€ ocorre antes da regiÃ£o paralela).
Rodar:

python numba_barreira.py

2) omp for bÃ¡sico (sem ID real de thread)

Arquivo: omp_for_numba.py
Mostra: prange e â€œworkers lÃ³gicosâ€ para ilustrar particionamento.
Nota: evite f-strings formatadas dentro de @njit.
Rodar:

python omp_for_numba.py

3) Contagem de primos paralela

Arquivo: off_primos_omp.py (versÃ£o Numba)
Mostra: paralelismo com prange, correÃ§Ã£o do passo 2 (usar k â†’ i=2*k+3).
Rodar:

python off_primos_omp.py 1000

4) firstprivate/private e map(to/from/alloc)

Arquivo: off_codigo1_numba.py
Mostra: escalar passado por valor (firstprivate), variÃ¡vel local por thread (private), cÃ³pias de entrada/saÃ­da (to/from) e alocaÃ§Ã£o temporÃ¡ria (alloc).
ObservaÃ§Ã£o: hÃ¡ fallback automÃ¡tico para CPU; se quiser forÃ§ar CPU:

# Windows cmd
set NUMBA_DISABLE_CUDA=1
# Linux/macOS
export NUMBA_DISABLE_CUDA=1


Rodar:

python off_codigo1_numba.py

5) DependÃªncias entre regiÃµes (depend/nowait)

Arquivo: off_depend_nowait_numba.py
Mostra: pipeline em duas fases independentes, garantindo ordem via chamadas sequenciais:

b = 2*a

c = b + 5
Rodar:

python off_depend_nowait_numba.py

6) collapse(2) + lastprivate

Arquivo: omp_collapse_numba.py
Mostra: linearizaÃ§Ã£o do par (k,j) e recuperaÃ§Ã£o do â€œÃºltimoâ€ (kmax, jmax).
Rodar:

python omp_collapse_numba.py

6.1) Benchmark de collapse: speedup e eficiÃªncia

Arquivo: collapse_benchmark_numba.py
Rodar:

python collapse_benchmark_numba.py

7) Dijkstra (menor caminho a partir de 0)

Relaxamento paralelo (prange) â€” seleÃ§Ã£o do mÃ­nimo sequencial:

Core: dijkstra_numba.py

Benchmark (speedup/eficiÃªncia):

dijkstra_numba_bench.py

Exemplo didÃ¡tico com reconstruÃ§Ã£o de rota:

dijkstra_exemplo_didatico.py

Rodar:

python dijkstra_numba.py
python dijkstra_numba_bench.py
python dijkstra_exemplo_didatico.py

8) map(to/from/alloc) em pipeline vetorial

TrÃªs estÃ¡gios (c=a+b; x=2*a alocado e usado localmente; ROI):
Arquivo: off_map_numba.py

Problema acadÃªmico + benchmark de estÃ¡gios:
Arquivo: pipeline_map_numba_bench.py

Rodar:

python off_map_numba.py
python pipeline_map_numba_bench.py

9) Jacobi 2D (Laplace) com fronteiras fixas

Arquivo: jacobi_numba.py
Mostra: atualizaÃ§Ã£o interior paralela e reduÃ§Ã£o max em duas fases.
Rodar:

python jacobi_numba.py

10) Poisson 2D (soluÃ§Ã£o manufaturada) â€” validaÃ§Ã£o e estudo de malha

Arquivo: jacobi_poisson_numba.py
Mostra: ajuste do Jacobi para Poisson (inclui RHS), cÃ¡lculo de erros L2/Lâˆ e logs de convergÃªncia.
Rodar:

python jacobi_poisson_numba.py

11) MPI + Numba (hÃ­brido) â€” Poisson 2D distribuÃ­do

Arquivo: dpois_mpi_numba.py
Mostra: decomposiÃ§Ã£o 1D em faixas de linhas, troca de halos com Sendrecv, reduÃ§Ãµes globais (allreduce), e paralelismo interno por processo com Numba.

Exemplo (4 processos, 4 threads/proc):

# Windows (PowerShell)
$env:NUMBA_NUM_THREADS="4"
mpirun -np 4 python dpois_mpi_numba.py --nx 1024 --ny 1024 --tol 1e-4 --max-it 8000 --omega 0.8 --threads 4 --report-every 200

# Linux/macOS
export NUMBA_NUM_THREADS=4
mpirun -np 4 python dpois_mpi_numba.py --nx 1024 --ny 1024 --tol 1e-4 --max-it 8000 --omega 0.8 --threads 4 --report-every 200

ğŸ§ª MediÃ§Ã£o: speedup & eficiÃªncia

Speedup: 
ğ‘†
ğ‘
=
ğ‘‡
1
/
ğ‘‡
ğ‘
S
p
	â€‹

=T
1
	â€‹

/T
p
	â€‹


EficiÃªncia: 
ğ¸
ğ‘
=
ğ‘†
ğ‘
/
ğ‘
E
p
	â€‹

=S
p
	â€‹

/p

Dicas:

FaÃ§a warm-up (chame o kernel uma vez) antes de cronometrar.

MeÃ§a vÃ¡rias vezes e use mediana.

Fixe NUMBA_NUM_THREADS para comparaÃ§Ãµes justas.

Armadilhas & SoluÃ§Ãµes

prange passo â‰  1 â†’ erro: â€œOnly constant step size of 1 is supportedâ€.
âœ… Use Ã­ndice auxiliar: k in prange(m) e mapeie i = 2*k+3, etc.

f-strings formatadas em @njit â†’ UnsupportedBytecodeError.
âœ… Use concatenaÃ§Ã£o ("txt "+str(i)) ou "%d".

print em funÃ§Ãµes jitted â†’ Ã© suportado mas lento/limitado; prefira imprimir no host.

CUDA (Numba-CUDA) â†’ cuidado com versÃµes. Numba requer CUDA Toolkit â‰¥ 11.2.
âœ… Se nÃ£o quiser GPU: NUMBA_DISABLE_CUDA=1.

ReduÃ§Ãµes (mÃ¡ximo/soma) â†’ para mÃ¡ximo, use duas fases (por linha â†’ global); soma simples pode ser direta em prange em muitos casos.
